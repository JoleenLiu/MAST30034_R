---
title: "sparklyr"
date: "`r Sys.Date()`"
author: Yue You
output:
  rmdformats::html_clean:
    self_contained: true
    thumbnails: true
    lightbox: true
    gallery: false
    highlight: tango
---

Spark needs to be installed first.
[Mac simple tutorial.](https://notadatascientist.com/install-spark-on-macos/)


### Load Data into SparklyR.

```{r, message=FALSE, warning=FALSE}
library(sparklyr)
library(dplyr)
sc <- spark_connect(master = "local")
nyc_taxi <- spark_read_csv(sc, 
                           name = "taxi_data",
                           path ="/stornext/Home/data/allstaff/y/you.y/MAST30034_R/data/sample.csv", 
                           header = TRUE, delimiter = ",")
```
```{r}
src_tbls(sc)
```

### dplyr manipulations.

collect() retrieves data into a local tibble.

```{r, message=FALSE, warning=FALSE}
passenger_summary <- nyc_taxi %>%
  group_by(passenger_count) %>% 
  summarise(count = n(), fare = mean(fare_amount), dist = mean(trip_distance)) %>% 
  filter(count > 200) %>% 
  collect
```

```{r, message=FALSE, warning=FALSE}
library(ggplot2)
ggplot(passenger_summary) +
  geom_point(aes(x=fare,y=dist,col=log(count),size=passenger_count)) +
  theme_bw()
```

### Machine Learning

You can orchestrate machine learning algorithms in a Spark cluster via the machine learning functions within sparklyr. These functions connect to a set of high-level APIs built on top of DataFrames that help you create and tune machine learning workflows.

Hereâ€™s an example where we use ml_linear_regression to fit a linear regression model.


```{r}
fit <- nyc_taxi %>%
  ml_linear_regression(total_amount ~ tip_amount + passenger_count)
```

For linear regression models produced by Spark, we can use summary() to learn a bit more about the quality of our fit, and the statistical significance of each of our predictors.

```{r}
summary(fit)
```




